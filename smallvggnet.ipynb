{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore') # Wow nice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import BatchNormalization, Conv2D, MaxPooling2D, Activation, Flatten, Dropout, Dense\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.preprocessing.image import img_to_array, ImageDataGenerator\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "matplotlib.use('Agg') # Non-interactive\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.feature_extraction.image import extract_patches_2d\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import numpy as np\n",
    "from imutils import paths\n",
    "import cv2\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SmallVGGNet(object):\n",
    "    @staticmethod\n",
    "    def build(width, height, num_classes, depth=3): # Depth is 3 cuz' RGB color-space\n",
    "        model = Sequential()\n",
    "        input_shape = (height, width, depth)\n",
    "        chan_dim = -1 # Index of the channel dimension (in order to apply BN)\n",
    "        \n",
    "        # First layers set ((Conv => ReLU => BN) * 2 => POOL => DO)\n",
    "        # 32 filters\n",
    "        model.add(Conv2D(32, (3, 3), padding='same', input_shape=input_shape))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization(axis=chan_dim))\n",
    "        model.add(Conv2D(32, (3, 3), padding='same'))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization(axis=chan_dim))\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2))) # Implicit stride of 2x2\n",
    "        model.add(Dropout(0.25))\n",
    "        \n",
    "        # Second layers set ((Conv => ReLU => BN) * 2 => POOL => DO)\n",
    "        # 64 filters\n",
    "        model.add(Conv2D(64, (3, 3), padding='same'))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization(axis=chan_dim))\n",
    "        model.add(Conv2D(64, (3, 3), padding='same'))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization(axis=chan_dim))\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "        model.add(Dropout(0.25))\n",
    "        \n",
    "        # FC layers set (FC => ReLU)\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(512))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Dropout(0.5))\n",
    "        \n",
    "        # Softmax Classifier\n",
    "        model.add(Dense(num_classes)) # Determined by the number of classes\n",
    "        model.add(Activation('softmax'))\n",
    "        \n",
    "        print(model.summary())\n",
    "        \n",
    "        return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_8 (Conv2D)            (None, 32, 32, 32)        896       \n",
      "_________________________________________________________________\n",
      "activation_12 (Activation)   (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_10 (B (None, 32, 32, 32)        128       \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 32, 32, 32)        9248      \n",
      "_________________________________________________________________\n",
      "activation_13 (Activation)   (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_11 (B (None, 32, 32, 32)        128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 16, 16, 64)        18496     \n",
      "_________________________________________________________________\n",
      "activation_14 (Activation)   (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_12 (B (None, 16, 16, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 16, 16, 64)        36928     \n",
      "_________________________________________________________________\n",
      "activation_15 (Activation)   (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_13 (B (None, 16, 16, 64)        256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 512)               2097664   \n",
      "_________________________________________________________________\n",
      "activation_16 (Activation)   (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_14 (B (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 3)                 1539      \n",
      "_________________________________________________________________\n",
      "activation_17 (Activation)   (None, 3)                 0         \n",
      "=================================================================\n",
      "Total params: 2,167,587\n",
      "Trainable params: 2,166,179\n",
      "Non-trainable params: 1,408\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "net = SmallVGGNet()\n",
    "model = net.build(32, 32, num_classes=3) # Using 3 classes Dog, Cat and Panda"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading, processing and splitting the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Loading Animals dataset...\n",
      "Samples: ['animals/dogs/dogs_00977.jpg', 'animals/dogs/dogs_00963.jpg', 'animals/dogs/dogs_00793.jpg', 'animals/dogs/dogs_00787.jpg', 'animals/dogs/dogs_00778.jpg']\n",
      "# Animals dataset loaded!\n"
     ]
    }
   ],
   "source": [
    "print('# Loading Animals dataset...')\n",
    "# trainX = training set datapoints, trainY = training set labels\n",
    "# Same of testing set\n",
    "image_paths = list(paths.list_images('animals'))\n",
    "print('Samples:', image_paths[0: 5])\n",
    "print('# Animals dataset loaded!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resize images and get labels\n",
    "images = []\n",
    "labels = []\n",
    "for path in image_paths:\n",
    "    # Looad the image\n",
    "    image = cv2.imread(path)\n",
    "    # Resize the image\n",
    "    image = cv2.resize(image, (32, 32), interpolation=cv2.INTER_AREA)\n",
    "    # Extract a random crop from the image\n",
    "    image = extract_patches_2d(image, (32, 32), max_patches=1)[0]\n",
    "    # Transform image to array\n",
    "    image = img_to_array(image, data_format=None)\n",
    "    # Append image and its associate label\n",
    "    images.append(image)\n",
    "    labels.append(path.split(os.path.sep)[-2])\n",
    "\n",
    "# Convert the dataset to numpy array\n",
    "images = np.array(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the pixel intensity values to the range [0, 1]\n",
    "def normalize(images):\n",
    "    return images.astype('float') / 255.0\n",
    "\n",
    "images = normalize(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets 75/25\n",
    "(trainX, testX, trainY, testY) = train_test_split(images, labels, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the labels from integers to vectors\n",
    "lb = LabelBinarizer()\n",
    "trainY = lb.fit_transform(trainY)\n",
    "testY = lb.fit_transform(testY)\n",
    "print('After converting:', trainY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set labels names for easier reading\n",
    "label_names = ['Dog', 'Cat', 'Panda']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle data augmentation\n",
    "daug = ImageDataGenerator(rotation_range=10, width_shift_range=0.1, height_shift_range=0.1,\n",
    "                         shear_range=0.2, zoom_range=0.2, horizontal_flip=True, fill_mode='nearest')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the number of epochs (times dataset has been seen)\n",
    "num_epochs = 50\n",
    "# Set the optimizer (here using Stochastic Gradient Descent with a learning rate of X, epochs-based decay and a momentum)\n",
    "# Decay slowly reduces the learning rate to reduce overfitting and get higher classification accc\n",
    "sgd_opt = SGD(lr=0.0005, decay=0.01 / num_epochs, momentum=0.9, nesterov=True)\n",
    "# Compile the model\n",
    "print('# Compiling the model...')\n",
    "model.compile(loss='categorical_crossentropy', optimizer=sgd_opt, metrics=['accuracy'])\n",
    "# Train the network!\n",
    "print('# Training the network...')\n",
    "M = model.fit_generator(daug.flow(trainX, trainY, batch_size=64), validation_data=(testX, testY),\n",
    "                        epochs=num_epochs, steps_per_epoch=len(trainX), verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evalute the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evalutate the network\n",
    "print('# Trained the network! Evaluating...')\n",
    "preds = model.predict(testX, batch_size=64)\n",
    "print(classification_report(testY.argmax(axis=1),\n",
    "preds.argmax(axis=1), target_names=label_names))\n",
    "\n",
    "%matplotlib inline\n",
    "# Plot history to check for overfitting\n",
    "plt.style.use('ggplot')\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.plot(np.arange(0, num_epochs), M.history['loss'], label='train_loss')\n",
    "plt.plot(np.arange(0, num_epochs), M.history['val_loss'], label='val_loss')\n",
    "plt.plot(np.arange(0, num_epochs), M.history['acc'], label='train_accuracy')\n",
    "plt.plot(np.arange(0, num_epochs), M.history['val_acc'], label='val_accuracy')\n",
    "\n",
    "plt.title('Training Loss and Accuracy')\n",
    "plt.ylabel('Loss/Accuracy')\n",
    "plt.xlabel('Epoch #')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notes:\n",
    "\n",
    "- 1st attempt: [lr: 0.005, 50 epochs, epoch-based decay rate] : avg 75% acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
